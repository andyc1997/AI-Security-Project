{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuPebPM8Yj4d",
        "outputId": "7fc4a872-267c-40dc-a4f3-18f5d0bb917f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UNSW - Foundation of Cybersecurity/pcp/code/AttackVAE\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/UNSW - Foundation of Cybersecurity/pcp/code/AttackVAE\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "echo \"Script executed from: ${PWD}\"\n",
        "echo \"MNIST\"\n",
        "python ./train.py --dataset mnist --seed 100 --h_dim 10 --n_width 28 --n_height 28 --n_channels 1 --reduction_type sum --lr 1e-3 --max_epoch 500 --t_cost -1 \"/content/drive/My Drive/UNSW - Foundation of Cybersecurity/pcp/code/data/mnist-sampled-N10000.npz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PefZbGDmawib",
        "outputId": "f8390c0f-47b0-4b0a-e74d-16c26ef20395"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script executed from: /content/drive/MyDrive/UNSW - Foundation of Cybersecurity/pcp/code/AttackVAE\n",
            "MNIST\n",
            "2023-11-12 07:30:31.058 INFO train - <module>: Namespace(path='/content/drive/My Drive/UNSW - Foundation of Cybersecurity/pcp/code/data/mnist-sampled-N10000.npz', dataset='mnist', p_feat=256, n_width=28, n_height=28, n_channels=1, h_dim=10, lr=0.001, batch_size=256, max_epoch=500, l_cost=100.0, t_cost=-1.0, custom_loss='MSE', reduction_type='sum', seed=100)\n",
            "2023-11-12 07:30:31.245 INFO train - <module>: ******************************\n",
            "Model: VAE\n",
            "******************************\n",
            "2023-11-12 07:30:31.276 INFO train - <module>: Using cuda device\n",
            "2023-11-12 07:30:35.880 INFO train - <module>: epoch: 0\t avg. loss:  3748.4875\n",
            "2023-11-12 07:30:36.763 INFO train - <module>: epoch: 1\t avg. loss:  2311.8978\n",
            "2023-11-12 07:30:37.591 INFO train - <module>: epoch: 2\t avg. loss:  2121.5589\n",
            "2023-11-12 07:30:38.567 INFO train - <module>: epoch: 3\t avg. loss:  1941.9045\n",
            "2023-11-12 07:30:39.401 INFO train - <module>: epoch: 4\t avg. loss:  1766.5128\n",
            "2023-11-12 07:30:40.355 INFO train - <module>: epoch: 5\t avg. loss:  1623.3931\n",
            "2023-11-12 07:30:41.171 INFO train - <module>: epoch: 6\t avg. loss:  1539.0761\n",
            "2023-11-12 07:30:42.079 INFO train - <module>: epoch: 7\t avg. loss:  1482.4990\n",
            "2023-11-12 07:30:42.981 INFO train - <module>: epoch: 8\t avg. loss:  1444.1834\n",
            "2023-11-12 07:30:43.822 INFO train - <module>: epoch: 9\t avg. loss:  1410.5077\n",
            "2023-11-12 07:30:44.734 INFO train - <module>: epoch: 10\t avg. loss:  1380.4879\n",
            "2023-11-12 07:30:45.656 INFO train - <module>: epoch: 11\t avg. loss:  1358.2460\n",
            "2023-11-12 07:30:46.553 INFO train - <module>: epoch: 12\t avg. loss:  1339.0282\n",
            "2023-11-12 07:30:47.465 INFO train - <module>: epoch: 13\t avg. loss:  1321.4467\n",
            "2023-11-12 07:30:48.323 INFO train - <module>: epoch: 14\t avg. loss:  1307.7983\n",
            "2023-11-12 07:30:49.167 INFO train - <module>: epoch: 15\t avg. loss:  1296.1570\n",
            "2023-11-12 07:30:50.030 INFO train - <module>: epoch: 16\t avg. loss:  1283.0379\n",
            "2023-11-12 07:30:50.924 INFO train - <module>: epoch: 17\t avg. loss:  1275.9661\n",
            "2023-11-12 07:30:51.793 INFO train - <module>: epoch: 18\t avg. loss:  1267.5589\n",
            "2023-11-12 07:30:52.627 INFO train - <module>: epoch: 19\t avg. loss:  1259.8435\n",
            "2023-11-12 07:30:53.470 INFO train - <module>: epoch: 20\t avg. loss:  1253.6879\n",
            "2023-11-12 07:30:54.320 INFO train - <module>: epoch: 21\t avg. loss:  1246.7440\n",
            "2023-11-12 07:30:55.183 INFO train - <module>: epoch: 22\t avg. loss:  1240.3777\n",
            "2023-11-12 07:30:56.124 INFO train - <module>: epoch: 23\t avg. loss:  1236.5563\n",
            "2023-11-12 07:30:56.971 INFO train - <module>: epoch: 24\t avg. loss:  1228.4360\n",
            "2023-11-12 07:30:58.009 INFO train - <module>: epoch: 25\t avg. loss:  1226.0621\n",
            "2023-11-12 07:30:58.901 INFO train - <module>: epoch: 26\t avg. loss:  1221.5819\n",
            "2023-11-12 07:30:59.855 INFO train - <module>: epoch: 27\t avg. loss:  1219.2480\n",
            "2023-11-12 07:31:00.798 INFO train - <module>: epoch: 28\t avg. loss:  1217.3989\n",
            "2023-11-12 07:31:01.658 INFO train - <module>: epoch: 29\t avg. loss:  1212.1288\n",
            "2023-11-12 07:31:02.522 INFO train - <module>: epoch: 30\t avg. loss:  1209.4791\n",
            "2023-11-12 07:31:03.373 INFO train - <module>: epoch: 31\t avg. loss:  1206.8295\n",
            "2023-11-12 07:31:04.227 INFO train - <module>: epoch: 32\t avg. loss:  1205.8764\n",
            "2023-11-12 07:31:05.089 INFO train - <module>: epoch: 33\t avg. loss:  1201.4919\n",
            "2023-11-12 07:31:05.938 INFO train - <module>: epoch: 34\t avg. loss:  1198.9931\n",
            "2023-11-12 07:31:06.767 INFO train - <module>: epoch: 35\t avg. loss:  1194.8177\n",
            "2023-11-12 07:31:07.746 INFO train - <module>: epoch: 36\t avg. loss:  1194.9486\n",
            "2023-11-12 07:31:08.598 INFO train - <module>: epoch: 37\t avg. loss:  1192.6993\n",
            "2023-11-12 07:31:09.597 INFO train - <module>: epoch: 38\t avg. loss:  1190.2169\n",
            "2023-11-12 07:31:10.486 INFO train - <module>: epoch: 39\t avg. loss:  1187.5534\n",
            "2023-11-12 07:31:11.426 INFO train - <module>: epoch: 40\t avg. loss:  1181.8989\n",
            "2023-11-12 07:31:12.320 INFO train - <module>: epoch: 41\t avg. loss:  1183.2895\n",
            "2023-11-12 07:31:13.208 INFO train - <module>: epoch: 42\t avg. loss:  1179.7876\n",
            "2023-11-12 07:31:14.160 INFO train - <module>: epoch: 43\t avg. loss:  1180.5029\n",
            "2023-11-12 07:31:15.094 INFO train - <module>: epoch: 44\t avg. loss:  1175.7153\n",
            "2023-11-12 07:31:16.002 INFO train - <module>: epoch: 45\t avg. loss:  1173.6579\n",
            "2023-11-12 07:31:16.907 INFO train - <module>: epoch: 46\t avg. loss:  1174.4236\n",
            "2023-11-12 07:31:17.749 INFO train - <module>: epoch: 47\t avg. loss:  1170.9172\n",
            "2023-11-12 07:31:18.574 INFO train - <module>: epoch: 48\t avg. loss:  1168.1851\n",
            "2023-11-12 07:31:19.438 INFO train - <module>: epoch: 49\t avg. loss:  1168.5237\n",
            "2023-11-12 07:31:20.261 INFO train - <module>: epoch: 50\t avg. loss:  1167.9155\n",
            "2023-11-12 07:31:21.087 INFO train - <module>: epoch: 51\t avg. loss:  1164.1953\n",
            "2023-11-12 07:31:21.953 INFO train - <module>: epoch: 52\t avg. loss:  1163.2385\n",
            "2023-11-12 07:31:22.810 INFO train - <module>: epoch: 53\t avg. loss:  1160.8470\n",
            "2023-11-12 07:31:23.621 INFO train - <module>: epoch: 54\t avg. loss:  1157.2400\n",
            "2023-11-12 07:31:24.452 INFO train - <module>: epoch: 55\t avg. loss:  1157.5434\n",
            "2023-11-12 07:31:25.326 INFO train - <module>: epoch: 56\t avg. loss:  1156.7558\n",
            "2023-11-12 07:31:26.275 INFO train - <module>: epoch: 57\t avg. loss:  1154.5549\n",
            "2023-11-12 07:31:27.186 INFO train - <module>: epoch: 58\t avg. loss:  1152.7610\n",
            "2023-11-12 07:31:28.091 INFO train - <module>: epoch: 59\t avg. loss:  1153.0600\n",
            "2023-11-12 07:31:29.056 INFO train - <module>: epoch: 60\t avg. loss:  1151.8209\n",
            "2023-11-12 07:31:30.055 INFO train - <module>: epoch: 61\t avg. loss:  1150.9259\n",
            "2023-11-12 07:31:30.959 INFO train - <module>: epoch: 62\t avg. loss:  1148.3631\n",
            "2023-11-12 07:31:31.862 INFO train - <module>: epoch: 63\t avg. loss:  1148.6963\n",
            "2023-11-12 07:31:32.669 INFO train - <module>: epoch: 64\t avg. loss:  1144.8477\n",
            "2023-11-12 07:31:33.512 INFO train - <module>: epoch: 65\t avg. loss:  1147.8281\n",
            "2023-11-12 07:31:34.352 INFO train - <module>: epoch: 66\t avg. loss:  1145.0325\n",
            "2023-11-12 07:31:35.173 INFO train - <module>: epoch: 67\t avg. loss:  1143.3485\n",
            "2023-11-12 07:31:36.095 INFO train - <module>: epoch: 68\t avg. loss:  1137.6838\n",
            "2023-11-12 07:31:37.134 INFO train - <module>: epoch: 69\t avg. loss:  1140.7923\n",
            "2023-11-12 07:31:38.021 INFO train - <module>: epoch: 70\t avg. loss:  1144.2276\n",
            "2023-11-12 07:31:38.838 INFO train - <module>: epoch: 71\t avg. loss:  1139.4046\n",
            "2023-11-12 07:31:39.790 INFO train - <module>: epoch: 72\t avg. loss:  1137.7525\n",
            "2023-11-12 07:31:40.730 INFO train - <module>: epoch: 73\t avg. loss:  1138.1001\n",
            "2023-11-12 07:31:41.683 INFO train - <module>: epoch: 74\t avg. loss:  1133.8570\n",
            "2023-11-12 07:31:42.612 INFO train - <module>: epoch: 75\t avg. loss:  1133.0468\n",
            "2023-11-12 07:31:43.525 INFO train - <module>: epoch: 76\t avg. loss:  1139.2754\n",
            "2023-11-12 07:31:44.338 INFO train - <module>: epoch: 77\t avg. loss:  1134.7555\n",
            "2023-11-12 07:31:45.141 INFO train - <module>: epoch: 78\t avg. loss:  1133.8957\n",
            "2023-11-12 07:31:46.075 INFO train - <module>: epoch: 79\t avg. loss:  1130.8686\n",
            "2023-11-12 07:31:46.916 INFO train - <module>: epoch: 80\t avg. loss:  1130.7736\n",
            "2023-11-12 07:31:47.805 INFO train - <module>: epoch: 81\t avg. loss:  1132.5866\n",
            "2023-11-12 07:31:48.679 INFO train - <module>: epoch: 82\t avg. loss:  1127.4543\n",
            "2023-11-12 07:31:49.660 INFO train - <module>: epoch: 83\t avg. loss:  1126.6972\n",
            "2023-11-12 07:31:50.498 INFO train - <module>: epoch: 84\t avg. loss:  1128.6299\n",
            "2023-11-12 07:31:51.321 INFO train - <module>: epoch: 85\t avg. loss:  1125.1580\n",
            "2023-11-12 07:31:52.186 INFO train - <module>: epoch: 86\t avg. loss:  1123.5822\n",
            "2023-11-12 07:31:53.041 INFO train - <module>: epoch: 87\t avg. loss:  1123.0913\n",
            "2023-11-12 07:31:53.944 INFO train - <module>: epoch: 88\t avg. loss:  1123.3313\n",
            "2023-11-12 07:31:54.925 INFO train - <module>: epoch: 89\t avg. loss:  1121.9699\n",
            "2023-11-12 07:31:55.812 INFO train - <module>: epoch: 90\t avg. loss:  1120.1743\n",
            "2023-11-12 07:31:56.780 INFO train - <module>: epoch: 91\t avg. loss:  1122.1379\n",
            "2023-11-12 07:31:57.728 INFO train - <module>: epoch: 92\t avg. loss:  1120.0765\n",
            "2023-11-12 07:31:58.618 INFO train - <module>: epoch: 93\t avg. loss:  1120.3768\n",
            "2023-11-12 07:31:59.433 INFO train - <module>: epoch: 94\t avg. loss:  1118.8138\n",
            "2023-11-12 07:32:00.256 INFO train - <module>: epoch: 95\t avg. loss:  1117.0914\n",
            "2023-11-12 07:32:01.093 INFO train - <module>: epoch: 96\t avg. loss:  1119.8845\n",
            "2023-11-12 07:32:01.902 INFO train - <module>: epoch: 97\t avg. loss:  1116.3900\n",
            "2023-11-12 07:32:02.742 INFO train - <module>: epoch: 98\t avg. loss:  1116.0782\n",
            "2023-11-12 07:32:03.629 INFO train - <module>: epoch: 99\t avg. loss:  1119.0153\n",
            "2023-11-12 07:32:04.471 INFO train - <module>: epoch: 100\t avg. loss:  1111.5645\n",
            "2023-11-12 07:32:05.310 INFO train - <module>: epoch: 101\t avg. loss:  1113.5965\n",
            "2023-11-12 07:32:06.129 INFO train - <module>: epoch: 102\t avg. loss:  1114.6363\n",
            "2023-11-12 07:32:06.983 INFO train - <module>: epoch: 103\t avg. loss:  1113.4681\n",
            "2023-11-12 07:32:07.854 INFO train - <module>: epoch: 104\t avg. loss:  1111.3887\n",
            "2023-11-12 07:32:08.759 INFO train - <module>: epoch: 105\t avg. loss:  1112.0633\n",
            "2023-11-12 07:32:09.713 INFO train - <module>: epoch: 106\t avg. loss:  1110.2285\n",
            "2023-11-12 07:32:10.585 INFO train - <module>: epoch: 107\t avg. loss:  1111.7356\n",
            "2023-11-12 07:32:11.468 INFO train - <module>: epoch: 108\t avg. loss:  1108.2755\n",
            "2023-11-12 07:32:12.363 INFO train - <module>: epoch: 109\t avg. loss:  1107.9952\n",
            "2023-11-12 07:32:13.198 INFO train - <module>: epoch: 110\t avg. loss:  1108.3309\n",
            "2023-11-12 07:32:14.033 INFO train - <module>: epoch: 111\t avg. loss:  1108.4015\n",
            "2023-11-12 07:32:14.859 INFO train - <module>: epoch: 112\t avg. loss:  1106.5761\n",
            "2023-11-12 07:32:15.809 INFO train - <module>: epoch: 113\t avg. loss:  1106.9055\n",
            "2023-11-12 07:32:16.729 INFO train - <module>: epoch: 114\t avg. loss:  1105.9972\n",
            "2023-11-12 07:32:17.617 INFO train - <module>: epoch: 115\t avg. loss:  1104.6728\n",
            "2023-11-12 07:32:18.502 INFO train - <module>: epoch: 116\t avg. loss:  1104.0416\n",
            "2023-11-12 07:32:19.363 INFO train - <module>: epoch: 117\t avg. loss:  1106.1131\n",
            "2023-11-12 07:32:20.182 INFO train - <module>: epoch: 118\t avg. loss:  1105.5263\n",
            "2023-11-12 07:32:21.008 INFO train - <module>: epoch: 119\t avg. loss:  1103.1764\n",
            "2023-11-12 07:32:21.891 INFO train - <module>: epoch: 120\t avg. loss:  1103.0837\n",
            "2023-11-12 07:32:22.846 INFO train - <module>: epoch: 121\t avg. loss:  1102.9680\n",
            "2023-11-12 07:32:23.754 INFO train - <module>: epoch: 122\t avg. loss:  1100.3443\n",
            "2023-11-12 07:32:24.651 INFO train - <module>: epoch: 123\t avg. loss:  1100.5244\n",
            "2023-11-12 07:32:25.554 INFO train - <module>: epoch: 124\t avg. loss:  1102.0070\n",
            "2023-11-12 07:32:26.477 INFO train - <module>: epoch: 125\t avg. loss:  1101.1570\n",
            "2023-11-12 07:32:27.365 INFO train - <module>: epoch: 126\t avg. loss:  1098.5006\n",
            "2023-11-12 07:32:28.195 INFO train - <module>: epoch: 127\t avg. loss:  1099.1113\n",
            "2023-11-12 07:32:29.060 INFO train - <module>: epoch: 128\t avg. loss:  1099.2913\n",
            "2023-11-12 07:32:29.907 INFO train - <module>: epoch: 129\t avg. loss:  1098.9219\n",
            "2023-11-12 07:32:30.721 INFO train - <module>: epoch: 130\t avg. loss:  1097.4469\n",
            "2023-11-12 07:32:31.553 INFO train - <module>: epoch: 131\t avg. loss:  1097.5533\n",
            "2023-11-12 07:32:32.477 INFO train - <module>: epoch: 132\t avg. loss:  1095.7506\n",
            "2023-11-12 07:32:33.383 INFO train - <module>: epoch: 133\t avg. loss:  1099.1419\n",
            "2023-11-12 07:32:34.308 INFO train - <module>: epoch: 134\t avg. loss:  1095.8863\n",
            "2023-11-12 07:32:35.211 INFO train - <module>: epoch: 135\t avg. loss:  1094.6455\n",
            "2023-11-12 07:32:36.185 INFO train - <module>: epoch: 136\t avg. loss:  1094.8197\n",
            "2023-11-12 07:32:37.101 INFO train - <module>: epoch: 137\t avg. loss:  1092.5157\n",
            "2023-11-12 07:32:37.968 INFO train - <module>: epoch: 138\t avg. loss:  1093.9346\n",
            "2023-11-12 07:32:38.847 INFO train - <module>: epoch: 139\t avg. loss:  1092.5612\n",
            "2023-11-12 07:32:39.690 INFO train - <module>: epoch: 140\t avg. loss:  1090.0875\n",
            "2023-11-12 07:32:40.634 INFO train - <module>: epoch: 141\t avg. loss:  1091.3562\n",
            "2023-11-12 07:32:41.546 INFO train - <module>: epoch: 142\t avg. loss:  1092.9613\n",
            "2023-11-12 07:32:42.470 INFO train - <module>: epoch: 143\t avg. loss:  1091.0477\n",
            "2023-11-12 07:32:43.295 INFO train - <module>: epoch: 144\t avg. loss:  1091.9717\n",
            "2023-11-12 07:32:44.113 INFO train - <module>: epoch: 145\t avg. loss:  1094.1444\n",
            "2023-11-12 07:32:44.916 INFO train - <module>: epoch: 146\t avg. loss:  1093.2452\n",
            "2023-11-12 07:32:45.736 INFO train - <module>: epoch: 147\t avg. loss:  1088.9348\n",
            "2023-11-12 07:32:46.566 INFO train - <module>: epoch: 148\t avg. loss:  1086.8718\n",
            "2023-11-12 07:32:47.404 INFO train - <module>: epoch: 149\t avg. loss:  1089.1919\n",
            "2023-11-12 07:32:48.224 INFO train - <module>: epoch: 150\t avg. loss:  1090.0990\n",
            "2023-11-12 07:32:49.048 INFO train - <module>: epoch: 151\t avg. loss:  1088.2944\n",
            "2023-11-12 07:32:49.871 INFO train - <module>: epoch: 152\t avg. loss:  1086.7772\n",
            "2023-11-12 07:32:50.856 INFO train - <module>: epoch: 153\t avg. loss:  1088.1209\n",
            "2023-11-12 07:32:51.737 INFO train - <module>: epoch: 154\t avg. loss:  1088.0051\n",
            "2023-11-12 07:32:52.656 INFO train - <module>: epoch: 155\t avg. loss:  1088.5065\n",
            "2023-11-12 07:32:53.563 INFO train - <module>: epoch: 156\t avg. loss:  1084.8389\n",
            "2023-11-12 07:32:54.537 INFO train - <module>: epoch: 157\t avg. loss:  1083.8210\n",
            "2023-11-12 07:32:55.381 INFO train - <module>: epoch: 158\t avg. loss:  1085.9565\n",
            "2023-11-12 07:32:56.378 INFO train - <module>: epoch: 159\t avg. loss:  1086.5608\n",
            "2023-11-12 07:32:57.361 INFO train - <module>: epoch: 160\t avg. loss:  1083.2131\n",
            "2023-11-12 07:32:58.260 INFO train - <module>: epoch: 161\t avg. loss:  1084.7480\n",
            "2023-11-12 07:32:59.144 INFO train - <module>: epoch: 162\t avg. loss:  1083.0392\n",
            "2023-11-12 07:33:00.038 INFO train - <module>: epoch: 163\t avg. loss:  1083.6802\n",
            "2023-11-12 07:33:00.862 INFO train - <module>: epoch: 164\t avg. loss:  1085.4105\n",
            "2023-11-12 07:33:01.709 INFO train - <module>: epoch: 165\t avg. loss:  1083.0899\n",
            "2023-11-12 07:33:02.542 INFO train - <module>: epoch: 166\t avg. loss:  1080.4127\n",
            "2023-11-12 07:33:03.444 INFO train - <module>: epoch: 167\t avg. loss:  1082.6222\n",
            "2023-11-12 07:33:04.365 INFO train - <module>: epoch: 168\t avg. loss:  1081.5737\n",
            "2023-11-12 07:33:05.243 INFO train - <module>: epoch: 169\t avg. loss:  1081.4963\n",
            "2023-11-12 07:33:06.139 INFO train - <module>: epoch: 170\t avg. loss:  1082.2829\n",
            "2023-11-12 07:33:07.096 INFO train - <module>: epoch: 171\t avg. loss:  1080.0480\n",
            "2023-11-12 07:33:08.053 INFO train - <module>: epoch: 172\t avg. loss:  1080.9778\n",
            "2023-11-12 07:33:08.932 INFO train - <module>: epoch: 173\t avg. loss:  1079.6705\n",
            "2023-11-12 07:33:09.756 INFO train - <module>: epoch: 174\t avg. loss:  1079.9891\n",
            "2023-11-12 07:33:10.607 INFO train - <module>: epoch: 175\t avg. loss:  1080.5961\n",
            "2023-11-12 07:33:11.454 INFO train - <module>: epoch: 176\t avg. loss:  1079.5412\n",
            "2023-11-12 07:33:12.330 INFO train - <module>: epoch: 177\t avg. loss:  1079.9892\n",
            "2023-11-12 07:33:13.229 INFO train - <module>: epoch: 178\t avg. loss:  1079.2882\n",
            "2023-11-12 07:33:14.059 INFO train - <module>: epoch: 179\t avg. loss:  1078.7756\n",
            "2023-11-12 07:33:14.900 INFO train - <module>: epoch: 180\t avg. loss:  1077.2259\n",
            "2023-11-12 07:33:15.722 INFO train - <module>: epoch: 181\t avg. loss:  1079.8667\n",
            "2023-11-12 07:33:16.550 INFO train - <module>: epoch: 182\t avg. loss:  1076.8753\n",
            "2023-11-12 07:33:17.395 INFO train - <module>: epoch: 183\t avg. loss:  1079.2779\n",
            "2023-11-12 07:33:18.247 INFO train - <module>: epoch: 184\t avg. loss:  1076.8974\n",
            "2023-11-12 07:33:19.136 INFO train - <module>: epoch: 185\t avg. loss:  1077.8663\n",
            "2023-11-12 07:33:19.978 INFO train - <module>: epoch: 186\t avg. loss:  1077.8244\n",
            "2023-11-12 07:33:20.865 INFO train - <module>: epoch: 187\t avg. loss:  1076.1636\n",
            "2023-11-12 07:33:21.752 INFO train - <module>: epoch: 188\t avg. loss:  1077.2404\n",
            "2023-11-12 07:33:22.706 INFO train - <module>: epoch: 189\t avg. loss:  1075.6122\n",
            "2023-11-12 07:33:23.584 INFO train - <module>: epoch: 190\t avg. loss:  1078.1524\n",
            "2023-11-12 07:33:24.398 INFO train - <module>: epoch: 191\t avg. loss:  1078.1234\n",
            "2023-11-12 07:33:25.241 INFO train - <module>: epoch: 192\t avg. loss:  1074.4612\n",
            "2023-11-12 07:33:26.054 INFO train - <module>: epoch: 193\t avg. loss:  1077.1374\n",
            "2023-11-12 07:33:26.885 INFO train - <module>: epoch: 194\t avg. loss:  1074.7203\n",
            "2023-11-12 07:33:27.762 INFO train - <module>: epoch: 195\t avg. loss:  1072.7864\n",
            "2023-11-12 07:33:28.609 INFO train - <module>: epoch: 196\t avg. loss:  1071.9767\n",
            "2023-11-12 07:33:29.461 INFO train - <module>: epoch: 197\t avg. loss:  1073.7090\n",
            "2023-11-12 07:33:30.298 INFO train - <module>: epoch: 198\t avg. loss:  1071.5845\n",
            "2023-11-12 07:33:31.200 INFO train - <module>: epoch: 199\t avg. loss:  1070.6372\n",
            "2023-11-12 07:33:32.008 INFO train - <module>: epoch: 200\t avg. loss:  1069.9709\n",
            "2023-11-12 07:33:32.889 INFO train - <module>: epoch: 201\t avg. loss:  1071.0857\n",
            "2023-11-12 07:33:33.813 INFO train - <module>: epoch: 202\t avg. loss:  1069.8105\n",
            "2023-11-12 07:33:34.772 INFO train - <module>: epoch: 203\t avg. loss:  1069.8910\n",
            "2023-11-12 07:33:35.662 INFO train - <module>: epoch: 204\t avg. loss:  1074.2063\n",
            "2023-11-12 07:33:36.520 INFO train - <module>: epoch: 205\t avg. loss:  1074.7716\n",
            "2023-11-12 07:33:37.366 INFO train - <module>: epoch: 206\t avg. loss:  1068.6344\n",
            "2023-11-12 07:33:38.164 INFO train - <module>: epoch: 207\t avg. loss:  1069.2273\n",
            "2023-11-12 07:33:38.970 INFO train - <module>: epoch: 208\t avg. loss:  1070.7239\n",
            "2023-11-12 07:33:39.817 INFO train - <module>: epoch: 209\t avg. loss:  1071.9507\n",
            "2023-11-12 07:33:40.637 INFO train - <module>: epoch: 210\t avg. loss:  1069.4916\n",
            "2023-11-12 07:33:41.505 INFO train - <module>: epoch: 211\t avg. loss:  1071.4932\n",
            "2023-11-12 07:33:42.460 INFO train - <module>: epoch: 212\t avg. loss:  1070.0014\n",
            "2023-11-12 07:33:43.374 INFO train - <module>: epoch: 213\t avg. loss:  1071.2220\n",
            "2023-11-12 07:33:44.198 INFO train - <module>: epoch: 214\t avg. loss:  1068.6231\n",
            "2023-11-12 07:33:45.050 INFO train - <module>: epoch: 215\t avg. loss:  1068.3160\n",
            "2023-11-12 07:33:45.860 INFO train - <module>: epoch: 216\t avg. loss:  1068.7207\n",
            "2023-11-12 07:33:46.681 INFO train - <module>: epoch: 217\t avg. loss:  1069.0651\n",
            "2023-11-12 07:33:47.522 INFO train - <module>: epoch: 218\t avg. loss:  1068.4806\n",
            "2023-11-12 07:33:48.457 INFO train - <module>: epoch: 219\t avg. loss:  1068.0787\n",
            "2023-11-12 07:33:49.382 INFO train - <module>: epoch: 220\t avg. loss:  1067.8427\n",
            "2023-11-12 07:33:50.289 INFO train - <module>: epoch: 221\t avg. loss:  1067.9961\n",
            "2023-11-12 07:33:51.187 INFO train - <module>: epoch: 222\t avg. loss:  1067.4375\n",
            "2023-11-12 07:33:52.047 INFO train - <module>: epoch: 223\t avg. loss:  1066.0109\n",
            "2023-11-12 07:33:52.876 INFO train - <module>: epoch: 224\t avg. loss:  1066.2708\n",
            "2023-11-12 07:33:53.700 INFO train - <module>: epoch: 225\t avg. loss:  1068.6227\n",
            "2023-11-12 07:33:54.509 INFO train - <module>: epoch: 226\t avg. loss:  1067.0108\n",
            "2023-11-12 07:33:55.358 INFO train - <module>: epoch: 227\t avg. loss:  1067.2682\n",
            "2023-11-12 07:33:56.228 INFO train - <module>: epoch: 228\t avg. loss:  1065.1186\n",
            "2023-11-12 07:33:57.091 INFO train - <module>: epoch: 229\t avg. loss:  1067.1856\n",
            "2023-11-12 07:33:57.975 INFO train - <module>: epoch: 230\t avg. loss:  1064.7113\n",
            "2023-11-12 07:33:58.817 INFO train - <module>: epoch: 231\t avg. loss:  1063.3398\n",
            "2023-11-12 07:33:59.617 INFO train - <module>: epoch: 232\t avg. loss:  1063.1840\n",
            "2023-11-12 07:34:00.480 INFO train - <module>: epoch: 233\t avg. loss:  1065.1801\n",
            "2023-11-12 07:34:01.328 INFO train - <module>: epoch: 234\t avg. loss:  1063.9951\n",
            "2023-11-12 07:34:02.206 INFO train - <module>: epoch: 235\t avg. loss:  1064.5449\n",
            "2023-11-12 07:34:03.068 INFO train - <module>: epoch: 236\t avg. loss:  1065.7495\n",
            "2023-11-12 07:34:03.975 INFO train - <module>: epoch: 237\t avg. loss:  1063.9000\n",
            "2023-11-12 07:34:04.916 INFO train - <module>: epoch: 238\t avg. loss:  1062.6206\n",
            "2023-11-12 07:34:05.781 INFO train - <module>: epoch: 239\t avg. loss:  1062.6931\n",
            "2023-11-12 07:34:06.658 INFO train - <module>: epoch: 240\t avg. loss:  1062.2520\n",
            "2023-11-12 07:34:07.527 INFO train - <module>: epoch: 241\t avg. loss:  1062.8645\n",
            "2023-11-12 07:34:08.345 INFO train - <module>: epoch: 242\t avg. loss:  1060.5783\n",
            "2023-11-12 07:34:09.175 INFO train - <module>: epoch: 243\t avg. loss:  1063.7382\n",
            "2023-11-12 07:34:10.026 INFO train - <module>: epoch: 244\t avg. loss:  1060.6544\n",
            "2023-11-12 07:34:10.889 INFO train - <module>: epoch: 245\t avg. loss:  1061.4711\n",
            "2023-11-12 07:34:11.733 INFO train - <module>: epoch: 246\t avg. loss:  1063.2102\n",
            "2023-11-12 07:34:12.664 INFO train - <module>: epoch: 247\t avg. loss:  1063.1799\n",
            "2023-11-12 07:34:13.539 INFO train - <module>: epoch: 248\t avg. loss:  1063.0786\n",
            "2023-11-12 07:34:14.356 INFO train - <module>: epoch: 249\t avg. loss:  1062.0015\n",
            "2023-11-12 07:34:15.260 INFO train - <module>: epoch: 250\t avg. loss:  1060.8723\n",
            "2023-11-12 07:34:16.183 INFO train - <module>: epoch: 251\t avg. loss:  1060.7496\n",
            "2023-11-12 07:34:17.109 INFO train - <module>: epoch: 252\t avg. loss:  1061.0343\n",
            "2023-11-12 07:34:17.980 INFO train - <module>: epoch: 253\t avg. loss:  1061.7533\n",
            "2023-11-12 07:34:18.846 INFO train - <module>: epoch: 254\t avg. loss:  1061.7051\n",
            "2023-11-12 07:34:19.768 INFO train - <module>: epoch: 255\t avg. loss:  1060.2700\n",
            "2023-11-12 07:34:20.661 INFO train - <module>: epoch: 256\t avg. loss:  1060.5472\n",
            "2023-11-12 07:34:21.471 INFO train - <module>: epoch: 257\t avg. loss:  1059.9370\n",
            "2023-11-12 07:34:22.313 INFO train - <module>: epoch: 258\t avg. loss:  1057.5835\n",
            "2023-11-12 07:34:23.184 INFO train - <module>: epoch: 259\t avg. loss:  1059.3123\n",
            "2023-11-12 07:34:24.094 INFO train - <module>: epoch: 260\t avg. loss:  1058.0180\n",
            "2023-11-12 07:34:24.927 INFO train - <module>: epoch: 261\t avg. loss:  1058.4711\n",
            "2023-11-12 07:34:25.770 INFO train - <module>: epoch: 262\t avg. loss:  1058.6765\n",
            "2023-11-12 07:34:26.634 INFO train - <module>: epoch: 263\t avg. loss:  1056.8392\n",
            "2023-11-12 07:34:27.602 INFO train - <module>: epoch: 264\t avg. loss:  1059.2803\n",
            "2023-11-12 07:34:28.450 INFO train - <module>: epoch: 265\t avg. loss:  1059.5875\n",
            "2023-11-12 07:34:29.271 INFO train - <module>: epoch: 266\t avg. loss:  1059.3832\n",
            "2023-11-12 07:34:30.169 INFO train - <module>: epoch: 267\t avg. loss:  1058.3796\n",
            "2023-11-12 07:34:31.032 INFO train - <module>: epoch: 268\t avg. loss:  1058.0271\n",
            "2023-11-12 07:34:31.883 INFO train - <module>: epoch: 269\t avg. loss:  1056.7940\n",
            "2023-11-12 07:34:32.811 INFO train - <module>: epoch: 270\t avg. loss:  1060.8802\n",
            "2023-11-12 07:34:33.655 INFO train - <module>: epoch: 271\t avg. loss:  1055.6722\n",
            "2023-11-12 07:34:34.484 INFO train - <module>: epoch: 272\t avg. loss:  1057.2615\n",
            "2023-11-12 07:34:35.319 INFO train - <module>: epoch: 273\t avg. loss:  1056.2432\n",
            "2023-11-12 07:34:36.155 INFO train - <module>: epoch: 274\t avg. loss:  1055.2700\n",
            "2023-11-12 07:34:37.021 INFO train - <module>: epoch: 275\t avg. loss:  1057.1782\n",
            "2023-11-12 07:34:37.939 INFO train - <module>: epoch: 276\t avg. loss:  1052.9950\n",
            "2023-11-12 07:34:38.801 INFO train - <module>: epoch: 277\t avg. loss:  1054.4985\n",
            "2023-11-12 07:34:39.645 INFO train - <module>: epoch: 278\t avg. loss:  1058.0410\n",
            "2023-11-12 07:34:40.480 INFO train - <module>: epoch: 279\t avg. loss:  1054.4413\n",
            "2023-11-12 07:34:41.368 INFO train - <module>: epoch: 280\t avg. loss:  1055.3016\n",
            "2023-11-12 07:34:42.208 INFO train - <module>: epoch: 281\t avg. loss:  1056.0092\n",
            "2023-11-12 07:34:43.142 INFO train - <module>: epoch: 282\t avg. loss:  1055.7728\n",
            "2023-11-12 07:34:43.975 INFO train - <module>: epoch: 283\t avg. loss:  1056.3465\n",
            "2023-11-12 07:34:44.887 INFO train - <module>: epoch: 284\t avg. loss:  1056.3492\n",
            "2023-11-12 07:34:45.726 INFO train - <module>: epoch: 285\t avg. loss:  1056.2237\n",
            "2023-11-12 07:34:46.632 INFO train - <module>: epoch: 286\t avg. loss:  1056.5184\n",
            "2023-11-12 07:34:47.535 INFO train - <module>: epoch: 287\t avg. loss:  1055.2975\n",
            "2023-11-12 07:34:48.330 INFO train - <module>: epoch: 288\t avg. loss:  1054.0240\n",
            "2023-11-12 07:34:49.129 INFO train - <module>: epoch: 289\t avg. loss:  1054.9534\n",
            "2023-11-12 07:34:49.952 INFO train - <module>: epoch: 290\t avg. loss:  1053.9995\n",
            "2023-11-12 07:34:50.779 INFO train - <module>: epoch: 291\t avg. loss:  1055.2500\n",
            "2023-11-12 07:34:51.599 INFO train - <module>: epoch: 292\t avg. loss:  1055.4583\n",
            "2023-11-12 07:34:52.439 INFO train - <module>: epoch: 293\t avg. loss:  1053.5376\n",
            "2023-11-12 07:34:53.285 INFO train - <module>: epoch: 294\t avg. loss:  1054.8292\n",
            "2023-11-12 07:34:54.081 INFO train - <module>: epoch: 295\t avg. loss:  1052.6121\n",
            "2023-11-12 07:34:54.959 INFO train - <module>: epoch: 296\t avg. loss:  1053.1097\n",
            "2023-11-12 07:34:55.776 INFO train - <module>: epoch: 297\t avg. loss:  1053.4970\n",
            "2023-11-12 07:34:56.581 INFO train - <module>: epoch: 298\t avg. loss:  1053.4784\n",
            "2023-11-12 07:34:57.488 INFO train - <module>: epoch: 299\t avg. loss:  1052.3939\n",
            "2023-11-12 07:34:58.375 INFO train - <module>: epoch: 300\t avg. loss:  1053.5959\n",
            "2023-11-12 07:34:59.274 INFO train - <module>: epoch: 301\t avg. loss:  1052.3010\n",
            "2023-11-12 07:35:00.199 INFO train - <module>: epoch: 302\t avg. loss:  1053.0627\n",
            "2023-11-12 07:35:01.097 INFO train - <module>: epoch: 303\t avg. loss:  1051.8574\n",
            "2023-11-12 07:35:01.987 INFO train - <module>: epoch: 304\t avg. loss:  1051.4380\n",
            "2023-11-12 07:35:02.799 INFO train - <module>: epoch: 305\t avg. loss:  1049.3362\n",
            "2023-11-12 07:35:03.644 INFO train - <module>: epoch: 306\t avg. loss:  1055.2385\n",
            "2023-11-12 07:35:04.468 INFO train - <module>: epoch: 307\t avg. loss:  1052.5887\n",
            "2023-11-12 07:35:05.303 INFO train - <module>: epoch: 308\t avg. loss:  1049.6176\n",
            "2023-11-12 07:35:06.138 INFO train - <module>: epoch: 309\t avg. loss:  1051.7107\n",
            "2023-11-12 07:35:07.061 INFO train - <module>: epoch: 310\t avg. loss:  1052.4805\n",
            "2023-11-12 07:35:07.893 INFO train - <module>: epoch: 311\t avg. loss:  1050.9949\n",
            "2023-11-12 07:35:08.714 INFO train - <module>: epoch: 312\t avg. loss:  1055.1622\n",
            "2023-11-12 07:35:09.533 INFO train - <module>: epoch: 313\t avg. loss:  1049.8204\n",
            "2023-11-12 07:35:10.343 INFO train - <module>: epoch: 314\t avg. loss:  1050.6893\n",
            "2023-11-12 07:35:11.208 INFO train - <module>: epoch: 315\t avg. loss:  1050.5134\n",
            "2023-11-12 07:35:12.145 INFO train - <module>: epoch: 316\t avg. loss:  1048.9040\n",
            "2023-11-12 07:35:13.044 INFO train - <module>: epoch: 317\t avg. loss:  1051.7987\n",
            "2023-11-12 07:35:13.975 INFO train - <module>: epoch: 318\t avg. loss:  1049.5235\n",
            "2023-11-12 07:35:14.889 INFO train - <module>: epoch: 319\t avg. loss:  1051.5683\n",
            "2023-11-12 07:35:15.768 INFO train - <module>: epoch: 320\t avg. loss:  1049.7607\n",
            "2023-11-12 07:35:16.658 INFO train - <module>: epoch: 321\t avg. loss:  1049.8827\n",
            "2023-11-12 07:35:17.598 INFO train - <module>: epoch: 322\t avg. loss:  1049.9855\n",
            "2023-11-12 07:35:18.432 INFO train - <module>: epoch: 323\t avg. loss:  1051.4848\n",
            "2023-11-12 07:35:19.272 INFO train - <module>: epoch: 324\t avg. loss:  1048.1050\n",
            "2023-11-12 07:35:20.132 INFO train - <module>: epoch: 325\t avg. loss:  1050.4676\n",
            "2023-11-12 07:35:20.995 INFO train - <module>: epoch: 326\t avg. loss:  1048.2290\n",
            "2023-11-12 07:35:21.966 INFO train - <module>: epoch: 327\t avg. loss:  1052.0791\n",
            "2023-11-12 07:35:22.821 INFO train - <module>: epoch: 328\t avg. loss:  1048.3186\n",
            "2023-11-12 07:35:23.636 INFO train - <module>: epoch: 329\t avg. loss:  1050.5257\n",
            "2023-11-12 07:35:24.441 INFO train - <module>: epoch: 330\t avg. loss:  1048.4608\n",
            "2023-11-12 07:35:25.247 INFO train - <module>: epoch: 331\t avg. loss:  1051.1852\n",
            "2023-11-12 07:35:26.086 INFO train - <module>: epoch: 332\t avg. loss:  1048.4315\n",
            "2023-11-12 07:35:26.957 INFO train - <module>: epoch: 333\t avg. loss:  1048.0643\n",
            "2023-11-12 07:35:27.825 INFO train - <module>: epoch: 334\t avg. loss:  1047.7969\n",
            "2023-11-12 07:35:28.687 INFO train - <module>: epoch: 335\t avg. loss:  1050.8512\n",
            "2023-11-12 07:35:29.537 INFO train - <module>: epoch: 336\t avg. loss:  1047.8060\n",
            "2023-11-12 07:35:30.352 INFO train - <module>: epoch: 337\t avg. loss:  1048.1516\n",
            "2023-11-12 07:35:31.152 INFO train - <module>: epoch: 338\t avg. loss:  1046.3631\n",
            "2023-11-12 07:35:32.011 INFO train - <module>: epoch: 339\t avg. loss:  1045.7934\n",
            "2023-11-12 07:35:32.879 INFO train - <module>: epoch: 340\t avg. loss:  1048.3473\n",
            "2023-11-12 07:35:33.719 INFO train - <module>: epoch: 341\t avg. loss:  1047.1395\n",
            "2023-11-12 07:35:34.565 INFO train - <module>: epoch: 342\t avg. loss:  1045.0065\n",
            "2023-11-12 07:35:35.437 INFO train - <module>: epoch: 343\t avg. loss:  1045.4808\n",
            "2023-11-12 07:35:36.321 INFO train - <module>: epoch: 344\t avg. loss:  1046.7853\n",
            "2023-11-12 07:35:37.135 INFO train - <module>: epoch: 345\t avg. loss:  1051.1654\n",
            "2023-11-12 07:35:37.941 INFO train - <module>: epoch: 346\t avg. loss:  1049.1414\n",
            "2023-11-12 07:35:38.771 INFO train - <module>: epoch: 347\t avg. loss:  1044.8100\n",
            "2023-11-12 07:35:39.598 INFO train - <module>: epoch: 348\t avg. loss:  1044.9511\n",
            "2023-11-12 07:35:40.500 INFO train - <module>: epoch: 349\t avg. loss:  1047.0991\n",
            "2023-11-12 07:35:41.367 INFO train - <module>: epoch: 350\t avg. loss:  1045.7113\n",
            "2023-11-12 07:35:42.282 INFO train - <module>: epoch: 351\t avg. loss:  1045.6878\n",
            "2023-11-12 07:35:43.085 INFO train - <module>: epoch: 352\t avg. loss:  1047.2973\n",
            "2023-11-12 07:35:43.981 INFO train - <module>: epoch: 353\t avg. loss:  1045.7570\n",
            "2023-11-12 07:35:44.868 INFO train - <module>: epoch: 354\t avg. loss:  1045.5181\n",
            "2023-11-12 07:35:45.679 INFO train - <module>: epoch: 355\t avg. loss:  1047.0107\n",
            "2023-11-12 07:35:46.488 INFO train - <module>: epoch: 356\t avg. loss:  1045.9237\n",
            "2023-11-12 07:35:47.321 INFO train - <module>: epoch: 357\t avg. loss:  1045.2781\n",
            "2023-11-12 07:35:48.127 INFO train - <module>: epoch: 358\t avg. loss:  1045.0000\n",
            "2023-11-12 07:35:48.942 INFO train - <module>: epoch: 359\t avg. loss:  1044.2719\n",
            "2023-11-12 07:35:49.818 INFO train - <module>: epoch: 360\t avg. loss:  1043.2206\n",
            "2023-11-12 07:35:50.639 INFO train - <module>: epoch: 361\t avg. loss:  1046.3619\n",
            "2023-11-12 07:35:51.508 INFO train - <module>: epoch: 362\t avg. loss:  1043.8343\n",
            "2023-11-12 07:35:52.355 INFO train - <module>: epoch: 363\t avg. loss:  1043.1006\n",
            "2023-11-12 07:35:53.223 INFO train - <module>: epoch: 364\t avg. loss:  1044.0936\n",
            "2023-11-12 07:35:54.049 INFO train - <module>: epoch: 365\t avg. loss:  1043.5931\n",
            "2023-11-12 07:35:54.893 INFO train - <module>: epoch: 366\t avg. loss:  1044.7911\n",
            "2023-11-12 07:35:55.744 INFO train - <module>: epoch: 367\t avg. loss:  1043.6584\n",
            "2023-11-12 07:35:56.702 INFO train - <module>: epoch: 368\t avg. loss:  1044.5301\n",
            "2023-11-12 07:35:57.641 INFO train - <module>: epoch: 369\t avg. loss:  1043.6893\n",
            "2023-11-12 07:35:58.598 INFO train - <module>: epoch: 370\t avg. loss:  1045.1999\n",
            "2023-11-12 07:35:59.437 INFO train - <module>: epoch: 371\t avg. loss:  1045.1686\n",
            "2023-11-12 07:36:00.344 INFO train - <module>: epoch: 372\t avg. loss:  1044.7245\n",
            "2023-11-12 07:36:01.251 INFO train - <module>: epoch: 373\t avg. loss:  1043.6413\n",
            "2023-11-12 07:36:02.091 INFO train - <module>: epoch: 374\t avg. loss:  1043.7433\n",
            "2023-11-12 07:36:02.912 INFO train - <module>: epoch: 375\t avg. loss:  1043.8188\n",
            "2023-11-12 07:36:03.710 INFO train - <module>: epoch: 376\t avg. loss:  1044.7087\n",
            "2023-11-12 07:36:04.515 INFO train - <module>: epoch: 377\t avg. loss:  1044.1666\n",
            "2023-11-12 07:36:05.325 INFO train - <module>: epoch: 378\t avg. loss:  1041.2413\n",
            "2023-11-12 07:36:06.221 INFO train - <module>: epoch: 379\t avg. loss:  1042.7940\n",
            "2023-11-12 07:36:07.127 INFO train - <module>: epoch: 380\t avg. loss:  1039.8332\n",
            "2023-11-12 07:36:08.125 INFO train - <module>: epoch: 381\t avg. loss:  1039.3744\n",
            "2023-11-12 07:36:09.140 INFO train - <module>: epoch: 382\t avg. loss:  1042.2113\n",
            "2023-11-12 07:36:09.987 INFO train - <module>: epoch: 383\t avg. loss:  1044.0482\n",
            "2023-11-12 07:36:10.940 INFO train - <module>: epoch: 384\t avg. loss:  1043.8461\n",
            "2023-11-12 07:36:11.861 INFO train - <module>: epoch: 385\t avg. loss:  1043.1688\n",
            "2023-11-12 07:36:12.744 INFO train - <module>: epoch: 386\t avg. loss:  1042.2909\n",
            "2023-11-12 07:36:13.610 INFO train - <module>: epoch: 387\t avg. loss:  1042.1685\n",
            "2023-11-12 07:36:14.504 INFO train - <module>: epoch: 388\t avg. loss:  1042.5946\n",
            "2023-11-12 07:36:15.403 INFO train - <module>: epoch: 389\t avg. loss:  1042.8809\n",
            "2023-11-12 07:36:16.392 INFO train - <module>: epoch: 390\t avg. loss:  1044.6019\n",
            "2023-11-12 07:36:17.310 INFO train - <module>: epoch: 391\t avg. loss:  1040.0895\n",
            "2023-11-12 07:36:18.204 INFO train - <module>: epoch: 392\t avg. loss:  1041.0394\n",
            "2023-11-12 07:36:19.092 INFO train - <module>: epoch: 393\t avg. loss:  1041.2013\n",
            "2023-11-12 07:36:20.023 INFO train - <module>: epoch: 394\t avg. loss:  1041.0768\n",
            "2023-11-12 07:36:20.861 INFO train - <module>: epoch: 395\t avg. loss:  1038.9862\n",
            "2023-11-12 07:36:21.747 INFO train - <module>: epoch: 396\t avg. loss:  1040.0769\n",
            "2023-11-12 07:36:22.622 INFO train - <module>: epoch: 397\t avg. loss:  1041.5909\n",
            "2023-11-12 07:36:23.508 INFO train - <module>: epoch: 398\t avg. loss:  1038.2206\n",
            "2023-11-12 07:36:24.412 INFO train - <module>: epoch: 399\t avg. loss:  1040.2589\n",
            "2023-11-12 07:36:25.271 INFO train - <module>: epoch: 400\t avg. loss:  1038.6864\n",
            "2023-11-12 07:36:26.116 INFO train - <module>: epoch: 401\t avg. loss:  1040.8212\n",
            "2023-11-12 07:36:27.005 INFO train - <module>: epoch: 402\t avg. loss:  1039.2804\n",
            "2023-11-12 07:36:27.824 INFO train - <module>: epoch: 403\t avg. loss:  1039.7855\n",
            "2023-11-12 07:36:28.644 INFO train - <module>: epoch: 404\t avg. loss:  1037.7321\n",
            "2023-11-12 07:36:29.485 INFO train - <module>: epoch: 405\t avg. loss:  1040.0167\n",
            "2023-11-12 07:36:30.299 INFO train - <module>: epoch: 406\t avg. loss:  1037.8787\n",
            "2023-11-12 07:36:31.091 INFO train - <module>: epoch: 407\t avg. loss:  1039.5126\n",
            "2023-11-12 07:36:31.935 INFO train - <module>: epoch: 408\t avg. loss:  1042.7193\n",
            "2023-11-12 07:36:32.742 INFO train - <module>: epoch: 409\t avg. loss:  1038.4013\n",
            "2023-11-12 07:36:33.598 INFO train - <module>: epoch: 410\t avg. loss:  1038.4745\n",
            "2023-11-12 07:36:34.431 INFO train - <module>: epoch: 411\t avg. loss:  1039.3917\n",
            "2023-11-12 07:36:35.253 INFO train - <module>: epoch: 412\t avg. loss:  1037.8069\n",
            "2023-11-12 07:36:36.137 INFO train - <module>: epoch: 413\t avg. loss:  1039.6201\n",
            "2023-11-12 07:36:36.967 INFO train - <module>: epoch: 414\t avg. loss:  1037.4852\n",
            "2023-11-12 07:36:37.848 INFO train - <module>: epoch: 415\t avg. loss:  1040.1542\n",
            "2023-11-12 07:36:38.676 INFO train - <module>: epoch: 416\t avg. loss:  1039.8225\n",
            "2023-11-12 07:36:39.577 INFO train - <module>: epoch: 417\t avg. loss:  1038.2577\n",
            "2023-11-12 07:36:40.536 INFO train - <module>: epoch: 418\t avg. loss:  1035.7679\n",
            "2023-11-12 07:36:41.478 INFO train - <module>: epoch: 419\t avg. loss:  1038.8791\n",
            "2023-11-12 07:36:42.376 INFO train - <module>: epoch: 420\t avg. loss:  1038.2206\n",
            "2023-11-12 07:36:43.265 INFO train - <module>: epoch: 421\t avg. loss:  1037.5921\n",
            "2023-11-12 07:36:44.140 INFO train - <module>: epoch: 422\t avg. loss:  1036.9020\n",
            "2023-11-12 07:36:44.945 INFO train - <module>: epoch: 423\t avg. loss:  1036.6705\n",
            "2023-11-12 07:36:45.749 INFO train - <module>: epoch: 424\t avg. loss:  1036.9799\n",
            "2023-11-12 07:36:46.558 INFO train - <module>: epoch: 425\t avg. loss:  1038.0578\n",
            "2023-11-12 07:36:47.399 INFO train - <module>: epoch: 426\t avg. loss:  1038.1990\n",
            "2023-11-12 07:36:48.301 INFO train - <module>: epoch: 427\t avg. loss:  1038.7121\n",
            "2023-11-12 07:36:49.202 INFO train - <module>: epoch: 428\t avg. loss:  1036.4614\n",
            "2023-11-12 07:36:50.090 INFO train - <module>: epoch: 429\t avg. loss:  1037.6762\n",
            "2023-11-12 07:36:51.019 INFO train - <module>: epoch: 430\t avg. loss:  1038.8176\n",
            "2023-11-12 07:36:51.968 INFO train - <module>: epoch: 431\t avg. loss:  1039.4668\n",
            "2023-11-12 07:36:52.813 INFO train - <module>: epoch: 432\t avg. loss:  1037.2261\n",
            "2023-11-12 07:36:53.757 INFO train - <module>: epoch: 433\t avg. loss:  1036.0352\n",
            "2023-11-12 07:36:54.642 INFO train - <module>: epoch: 434\t avg. loss:  1036.8470\n",
            "2023-11-12 07:36:55.517 INFO train - <module>: epoch: 435\t avg. loss:  1035.6649\n",
            "2023-11-12 07:36:56.425 INFO train - <module>: epoch: 436\t avg. loss:  1038.3982\n",
            "2023-11-12 07:36:57.482 INFO train - <module>: epoch: 437\t avg. loss:  1037.3285\n",
            "2023-11-12 07:36:58.257 INFO train - <module>: epoch: 438\t avg. loss:  1036.4230\n",
            "2023-11-12 07:36:59.076 INFO train - <module>: epoch: 439\t avg. loss:  1037.7752\n",
            "2023-11-12 07:36:59.884 INFO train - <module>: epoch: 440\t avg. loss:  1035.2754\n",
            "2023-11-12 07:37:00.809 INFO train - <module>: epoch: 441\t avg. loss:  1037.1127\n",
            "2023-11-12 07:37:01.636 INFO train - <module>: epoch: 442\t avg. loss:  1035.2260\n",
            "2023-11-12 07:37:02.516 INFO train - <module>: epoch: 443\t avg. loss:  1036.4562\n",
            "2023-11-12 07:37:03.343 INFO train - <module>: epoch: 444\t avg. loss:  1034.6581\n",
            "2023-11-12 07:37:04.225 INFO train - <module>: epoch: 445\t avg. loss:  1035.6781\n",
            "2023-11-12 07:37:05.079 INFO train - <module>: epoch: 446\t avg. loss:  1035.4842\n",
            "2023-11-12 07:37:06.005 INFO train - <module>: epoch: 447\t avg. loss:  1036.1494\n",
            "2023-11-12 07:37:06.876 INFO train - <module>: epoch: 448\t avg. loss:  1034.7770\n",
            "2023-11-12 07:37:07.770 INFO train - <module>: epoch: 449\t avg. loss:  1034.3076\n",
            "2023-11-12 07:37:08.701 INFO train - <module>: epoch: 450\t avg. loss:  1034.4658\n",
            "2023-11-12 07:37:09.554 INFO train - <module>: epoch: 451\t avg. loss:  1035.6095\n",
            "2023-11-12 07:37:10.431 INFO train - <module>: epoch: 452\t avg. loss:  1036.4585\n",
            "2023-11-12 07:37:11.254 INFO train - <module>: epoch: 453\t avg. loss:  1034.1038\n",
            "2023-11-12 07:37:12.160 INFO train - <module>: epoch: 454\t avg. loss:  1032.0058\n",
            "2023-11-12 07:37:12.994 INFO train - <module>: epoch: 455\t avg. loss:  1034.5762\n",
            "2023-11-12 07:37:13.807 INFO train - <module>: epoch: 456\t avg. loss:  1036.9194\n",
            "2023-11-12 07:37:14.633 INFO train - <module>: epoch: 457\t avg. loss:  1035.5450\n",
            "2023-11-12 07:37:15.456 INFO train - <module>: epoch: 458\t avg. loss:  1034.1078\n",
            "2023-11-12 07:37:16.273 INFO train - <module>: epoch: 459\t avg. loss:  1034.8214\n",
            "2023-11-12 07:37:17.090 INFO train - <module>: epoch: 460\t avg. loss:  1034.1970\n",
            "2023-11-12 07:37:17.900 INFO train - <module>: epoch: 461\t avg. loss:  1034.2506\n",
            "2023-11-12 07:37:18.730 INFO train - <module>: epoch: 462\t avg. loss:  1034.0906\n",
            "2023-11-12 07:37:19.603 INFO train - <module>: epoch: 463\t avg. loss:  1034.5538\n",
            "2023-11-12 07:37:20.464 INFO train - <module>: epoch: 464\t avg. loss:  1034.1302\n",
            "2023-11-12 07:37:21.329 INFO train - <module>: epoch: 465\t avg. loss:  1031.6574\n",
            "2023-11-12 07:37:22.318 INFO train - <module>: epoch: 466\t avg. loss:  1033.4997\n",
            "2023-11-12 07:37:23.219 INFO train - <module>: epoch: 467\t avg. loss:  1032.2247\n",
            "2023-11-12 07:37:24.061 INFO train - <module>: epoch: 468\t avg. loss:  1033.2001\n",
            "2023-11-12 07:37:24.904 INFO train - <module>: epoch: 469\t avg. loss:  1034.6046\n",
            "2023-11-12 07:37:25.825 INFO train - <module>: epoch: 470\t avg. loss:  1034.3985\n",
            "2023-11-12 07:37:26.725 INFO train - <module>: epoch: 471\t avg. loss:  1033.1733\n",
            "2023-11-12 07:37:27.556 INFO train - <module>: epoch: 472\t avg. loss:  1033.9409\n",
            "2023-11-12 07:37:28.390 INFO train - <module>: epoch: 473\t avg. loss:  1032.5747\n",
            "2023-11-12 07:37:29.217 INFO train - <module>: epoch: 474\t avg. loss:  1033.3026\n",
            "2023-11-12 07:37:30.032 INFO train - <module>: epoch: 475\t avg. loss:  1031.1699\n",
            "2023-11-12 07:37:30.855 INFO train - <module>: epoch: 476\t avg. loss:  1032.4172\n",
            "2023-11-12 07:37:31.671 INFO train - <module>: epoch: 477\t avg. loss:  1033.9353\n",
            "2023-11-12 07:37:32.478 INFO train - <module>: epoch: 478\t avg. loss:  1033.5256\n",
            "2023-11-12 07:37:33.323 INFO train - <module>: epoch: 479\t avg. loss:  1034.2438\n",
            "2023-11-12 07:37:34.208 INFO train - <module>: epoch: 480\t avg. loss:  1032.8879\n",
            "2023-11-12 07:37:35.155 INFO train - <module>: epoch: 481\t avg. loss:  1031.9962\n",
            "2023-11-12 07:37:36.024 INFO train - <module>: epoch: 482\t avg. loss:  1033.3120\n",
            "2023-11-12 07:37:36.964 INFO train - <module>: epoch: 483\t avg. loss:  1032.6696\n",
            "2023-11-12 07:37:37.855 INFO train - <module>: epoch: 484\t avg. loss:  1032.2207\n",
            "2023-11-12 07:37:38.702 INFO train - <module>: epoch: 485\t avg. loss:  1032.4305\n",
            "2023-11-12 07:37:39.629 INFO train - <module>: epoch: 486\t avg. loss:  1034.0426\n",
            "2023-11-12 07:37:40.531 INFO train - <module>: epoch: 487\t avg. loss:  1032.8524\n",
            "2023-11-12 07:37:41.338 INFO train - <module>: epoch: 488\t avg. loss:  1033.7292\n",
            "2023-11-12 07:37:42.250 INFO train - <module>: epoch: 489\t avg. loss:  1030.4212\n",
            "2023-11-12 07:37:43.069 INFO train - <module>: epoch: 490\t avg. loss:  1031.0874\n",
            "2023-11-12 07:37:43.940 INFO train - <module>: epoch: 491\t avg. loss:  1033.1908\n",
            "2023-11-12 07:37:44.847 INFO train - <module>: epoch: 492\t avg. loss:  1031.5030\n",
            "2023-11-12 07:37:45.657 INFO train - <module>: epoch: 493\t avg. loss:  1033.1935\n",
            "2023-11-12 07:37:46.446 INFO train - <module>: epoch: 494\t avg. loss:  1032.3674\n",
            "2023-11-12 07:37:47.255 INFO train - <module>: epoch: 495\t avg. loss:  1033.3290\n",
            "2023-11-12 07:37:48.198 INFO train - <module>: epoch: 496\t avg. loss:  1032.6346\n",
            "2023-11-12 07:37:49.087 INFO train - <module>: epoch: 497\t avg. loss:  1031.1790\n",
            "2023-11-12 07:37:50.004 INFO train - <module>: epoch: 498\t avg. loss:  1030.5974\n",
            "2023-11-12 07:37:50.980 INFO train - <module>: epoch: 499\t avg. loss:  1031.4367\n",
            "2023-11-12 07:37:50.981 INFO train - <module>: VAE finished Training. Lowest cost:  1030.4212\n",
            "2023-11-12 07:37:51.624 INFO train - <module>: Final computation finished.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}