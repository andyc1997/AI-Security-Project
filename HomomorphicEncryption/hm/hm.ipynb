{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsfIwQ8aBC7JOF8C5yqTKa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Colab does not come with tenseal preinstalled, so please install tenseal**\n","\n","\n","*   https://github.com/OpenMined/TenSEAL\n","\n"],"metadata":{"id":"b4EAWdyrS6fW"}},{"cell_type":"code","source":["!pip install tenseal"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiOdwiQHS4WG","executionInfo":{"status":"ok","timestamp":1713092959825,"user_tz":-480,"elapsed":16521,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}},"outputId":"1650baeb-484e-444b-f1e0-09727c3f9b91"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tenseal\n","  Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenseal\n","Successfully installed tenseal-0.3.14\n"]}]},{"cell_type":"markdown","source":["**Connection to Google Drive through Colab**"],"metadata":{"id":"42V-yP7qB2iD"}},{"cell_type":"code","source":["# Run this cell if you need to connect to G drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tDJfqG7BTa9","executionInfo":{"status":"ok","timestamp":1713094819338,"user_tz":-480,"elapsed":2694,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}},"outputId":"2b1cd8bd-1002-4265-83a8-1f97bcb482a9"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["**Path to project folder**"],"metadata":{"id":"nDgiBHSyBfSt"}},{"cell_type":"code","source":["%cd '/content/drive/My Drive/UNSW_CyberSecurity/UNSW_SecurityEngineering/Week 5/experiment/hm'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iprYQ_o2Bbif","executionInfo":{"status":"ok","timestamp":1713095212834,"user_tz":-480,"elapsed":18,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}},"outputId":"5e3fe0c3-9774-468a-e843-e1685477a986"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/UNSW_CyberSecurity/UNSW_SecurityEngineering/Week 5/experiment/hm\n"]}]},{"cell_type":"markdown","source":["**Packages**"],"metadata":{"id":"djNEHeb6-uRt"}},{"cell_type":"code","execution_count":84,"metadata":{"id":"R2i6co67-nfy","executionInfo":{"status":"ok","timestamp":1713095212834,"user_tz":-480,"elapsed":12,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"outputs":[],"source":["import numpy as np\n","import tenseal as ts\n","import time\n","import torch\n","import random\n","\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from tqdm import tqdm"]},{"cell_type":"markdown","source":["**Model architecture**"],"metadata":{"id":"Ll4Z8OXuTdF0"}},{"cell_type":"code","source":["class ConvNet(torch.nn.Module):\n","    def __init__(self, hidden=64, output=10):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n","        self.fc1 = torch.nn.Linear(256, hidden)\n","        self.fc2 = torch.nn.Linear(hidden, output)\n","        self.activation = torch.nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        # the model uses the square activation function\n","        x = self.activation(x)\n","        # flattening while keeping the batch axis\n","        x = x.view(-1, 256)\n","        x = self.fc1(x)\n","        x = self.activation(x)\n","        x = self.fc2(x)\n","        x = self.activation(x)\n","        return x"],"metadata":{"id":"i6jXV2POTaqb","executionInfo":{"status":"ok","timestamp":1713095212834,"user_tz":-480,"elapsed":11,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["class EncConvNet:\n","    def __init__(self, torch_nn):\n","        self.conv1_weight = torch_nn.conv1.weight.data.view(\n","            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n","            torch_nn.conv1.kernel_size[1]\n","        ).tolist()\n","        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n","\n","        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n","        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n","\n","        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n","        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n","\n","    def forward(self, enc_x, windows_nb):\n","        # conv layer\n","        enc_channels = []\n","        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n","            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n","            enc_channels.append(y)\n","        # pack all channels into a single flattened vector\n","        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n","        # square activation\n","        enc_x.polyval([0.5, 0.197, 0, -0.004])\n","        # fc1 layer\n","        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n","        # square activation\n","        enc_x.polyval([0.5, 0.197, 0, -0.004])\n","        # fc2 layer\n","        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n","        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n","\n","    def __call__(self, *args, **kwargs):\n","        return self.forward(*args, **kwargs)"],"metadata":{"id":"VE98ghA7UWt6","executionInfo":{"status":"ok","timestamp":1713095212835,"user_tz":-480,"elapsed":11,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["**Load Trained Model**"],"metadata":{"id":"P8If2g5WTzPh"}},{"cell_type":"code","source":["model = ConvNet()\n","model.load_state_dict(torch.load(r'../model/model.pth', map_location=torch.device('cpu')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPrnctqsTynC","executionInfo":{"status":"ok","timestamp":1713095212835,"user_tz":-480,"elapsed":10,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}},"outputId":"d9eb4044-497e-44c0-baf8-e257f8502372"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["**Load full dataset**"],"metadata":{"id":"tL2x-S0DVTOz"}},{"cell_type":"code","source":["# Convert from numpy array to torch tensor.\n","def preprocessing(X: np.ndarray):\n","    X = torch.Tensor(X).type(torch.float32)\n","    return X.view(X.size(0), 1, 28, 28)"],"metadata":{"id":"rqvMxkf3VS9J","executionInfo":{"status":"ok","timestamp":1713095212835,"user_tz":-480,"elapsed":8,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["# Data class for DataLoader\n","class MNIST_dataset(Dataset):\n","    def __init__(self, input, ouput):\n","        self.input = input\n","        self.ouput = ouput\n","\n","    def __getitem__(self, index):\n","        return self.input[index], self.ouput[index]\n","\n","    def __len__ (self):\n","        return len(self.input)"],"metadata":{"id":"sCpS5PQ2WSQr","executionInfo":{"status":"ok","timestamp":1713095212835,"user_tz":-480,"elapsed":7,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["ct = time.strftime('%Y%m%d-%H%M')\n","path = r'../data/mnist-sampled-N3500.npz'\n","data = np.load(path)\n","data_img = data.get(data.files[0]) / 255.0 # this is input data\n","data_lbl = data.get(data.files[1]) # this is numeric label\n","N = data_img.shape[0]\n","p = data_img.reshape(N, -1).shape[1]\n","\n","data_img = preprocessing(data_img)[:30]\n","data_lbl = F.one_hot(torch.Tensor(data_lbl).long(), num_classes=10).float()[:30] # One-hot key encoding\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"-KOiKgLdVlmR","executionInfo":{"status":"ok","timestamp":1713095212835,"user_tz":-480,"elapsed":7,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["data = MNIST_dataset(data_img, data_lbl)\n","train_loader = DataLoader(data, batch_size=1, shuffle=True)"],"metadata":{"id":"PYwV8kqVWOVK","executionInfo":{"status":"ok","timestamp":1713095213317,"user_tz":-480,"elapsed":5,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["def enc_test(context, model, train_loader, criterion, kernel_shape, stride):\n","    # initialize lists to monitor test loss and accuracy\n","    test_loss = 0.0\n","    class_correct = list(0. for i in range(10))\n","    class_total = list(0. for i in range(10))\n","\n","    for data, target in tqdm(train_loader):\n","        # Encoding and encryption\n","        x_enc, windows_nb = ts.im2col_encoding(\n","            context, data.view(28, 28).tolist(), kernel_shape[0],\n","            kernel_shape[1], stride\n","        )\n","        # Encrypted evaluation\n","        enc_output = enc_model(x_enc, windows_nb)\n","        # Decryption of result\n","        output = enc_output.decrypt()\n","        output = torch.tensor(output).view(1, -1)\n","\n","        # compute loss\n","        loss = criterion(output, target)\n","        test_loss += loss.item()\n","\n","        # convert output probabilities to predicted class\n","        _, pred = torch.max(output.data, 1)\n","        _, y = torch.max(target.data, 1)\n","        # compare predictions to true label\n","        correct = (pred == y).sum().item()\n","        # calculate accuracy for each object class\n","        label = y\n","        class_correct[label] += correct\n","        class_total[label] += 1\n","\n","\n","    # calculate and print avg loss\n","    test_loss = test_loss / sum(class_total)\n","    print(f'Test Loss: {test_loss:.6f}\\n')\n","\n","   # for label in range(10):\n","   #     print(\n","   #         f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n","   #         f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n","   #     )\n","\n","    print(\n","        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n","        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n","    )\n","\n","\n","\n","# required for encoding\n","kernel_shape = model.conv1.kernel_size\n","stride = model.conv1.stride[0]"],"metadata":{"id":"0gjgtpu6VvUW","executionInfo":{"status":"ok","timestamp":1713095213318,"user_tz":-480,"elapsed":5,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["## Encryption Parameters\n","\n","# controls precision of the fractional part\n","bits_scale = 26\n","\n","# Create TenSEAL context\n","context = ts.context(\n","    ts.SCHEME_TYPE.CKKS,\n","    poly_modulus_degree=8192,\n","    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",")\n","\n","# set the scale\n","context.global_scale = pow(2, bits_scale)\n","\n","# galois keys are required to do ciphertext rotations\n","context.generate_galois_keys()"],"metadata":{"id":"xJ5gCD2XWXue","executionInfo":{"status":"ok","timestamp":1713095214847,"user_tz":-480,"elapsed":1533,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["enc_model = EncConvNet(model)\n","enc_test(context, enc_model, train_loader, criterion, kernel_shape, stride)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-wvGXpgWYS6","executionInfo":{"status":"ok","timestamp":1713095493839,"user_tz":-480,"elapsed":279000,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}},"outputId":"e020f1a6-24fb-4f87-8931-4c4f0634964e"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [04:39<00:00,  9.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 735.005789\n","\n","\n","Test Accuracy (Overall): 23% (7/30)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def enc_test2(context, model, train_loader, criterion, kernel_shape, stride):\n","    # initialize lists to monitor test loss and accuracy\n","    test_loss = 0.0\n","    class_correct = list(0. for i in range(10))\n","    class_total = list(0. for i in range(10))\n","\n","    for data, target in tqdm(train_loader):\n","        output = model(data)\n","        # Decryption of result\n","        output = torch.tensor(output.detach()).view(1, -1)\n","\n","        # compute loss\n","        loss = criterion(output, target)\n","        test_loss += loss.item()\n","\n","        # convert output probabilities to predicted class\n","        _, pred = torch.max(output.data, 1)\n","        _, y = torch.max(target.data, 1)\n","        # compare predictions to true label\n","        correct = (pred == y).sum().item()\n","        # calculate accuracy for each object class\n","        label = y\n","        class_correct[label] += correct\n","        class_total[label] += 1\n","\n","\n","    # calculate and print avg loss\n","    test_loss = test_loss / sum(class_total)\n","    print(f'Test Loss: {test_loss:.6f}\\n')\n","\n","   # for label in range(10):\n","   #     print(\n","   #         f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n","   #         f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n","   #     )\n","\n","    print(\n","        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n","        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n","    )"],"metadata":{"id":"K5FoNfKQWyie","executionInfo":{"status":"ok","timestamp":1713095493840,"user_tz":-480,"elapsed":14,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["enc_test2(context, model, train_loader, criterion, kernel_shape, stride)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysNlAJkRa_uO","executionInfo":{"status":"ok","timestamp":1713095493841,"user_tz":-480,"elapsed":13,"user":{"displayName":"Wai Chun Cheung","userId":"01005985492029512712"}},"outputId":"93a26eb6-ecb5-4271-cf38-a51709fc656c"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/30 [00:00<?, ?it/s]<ipython-input-95-c9a0e36c798a>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  output = torch.tensor(output.detach()).view(1, -1)\n","100%|██████████| 30/30 [00:00<00:00, 965.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 1.461445\n","\n","\n","Test Accuracy (Overall): 100% (30/30)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}