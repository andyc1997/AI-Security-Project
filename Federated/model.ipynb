{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ugEUf06FlD2_d-vzIiBKeuPPDq7Yl9Ae","authorship_tag":"ABX9TyMmm+izaZCoNpZCbu99xoIj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSIsOQedod1m","executionInfo":{"status":"ok","timestamp":1700664138720,"user_tz":-480,"elapsed":7,"user":{"displayName":"Gamma Beta","userId":"01005985492029512712"}},"outputId":"87e1a22f-a40e-47f8-a796-0ede99fc7c00"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/UNSW - Foundation of Cybersecurity/pcp/code/Federated\n"]}],"source":["# Set path to working dir\n","%cd \"/content/drive/MyDrive/UNSW - Foundation of Cybersecurity/pcp/code/Federated\""]},{"cell_type":"code","source":["import json\n","import numpy as np\n","import os\n","import random\n","\n","from dataclasses import dataclass\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.svm import SVC\n","\n","\n","\n","@dataclass\n","class Device:\n","    id: int\n","    nsamples: int\n","    X: np.ndarray # data (train)\n","    y: np.ndarray # target (train)\n","    Xt: np.ndarray # data (test)\n","    yt: np.ndarray # target (test)\n","    params: dict = None\n","    metrics: float = None\n","\n","    def train(self):\n","        estimator = SVC(kernel=\"rbf\")\n","        param_grid = {\"C\": [1e-1, 1, 1e1, 1e2, 1e3],\n","                \"gamma\": [1e-2, 1e-1, 1, 1e1]}\n","        clf = GridSearchCV(estimator, param_grid, cv=3)\n","        clf.fit(self.X, self.y)\n","        self.metrics = clf.best_score_\n","        self.params = clf.best_params_\n","\n","    def send(self):\n","        estimator = SVC(kernel=\"rbf\", gamma=self.params['gamma'], C=self.params['C'])\n","        estimator.fit(self.X, self.y)\n","        test_score = accuracy_score(self.yt, estimator.predict(self.Xt))\n","        return estimator, self.metrics, self.nsamples, self.Xt, self.yt, test_score\n","\n","\n","class Ensemble:\n","    def __init__(self, estimators):\n","        self.estimators = estimators\n","        self.n_models = len(estimators)\n","\n","    def predict(self, X):\n","        scores = np.zeros(X.shape[0])\n","        for i in range(self.n_models):\n","            scores += self.estimators[i][\"estimator\"].predict(X)\n","        scores /= self.n_models\n","        return scores\n","\n","\n","class Server:\n","    def __init__(self):\n","        self.models = []\n","        self.ensemble = None\n","\n","    def build_ensemble(self, k, ensemble_type):\n","        if ensemble_type == \"random\":\n","            random.shuffle(self.models)\n","\n","        elif ensemble_type == \"cv\":\n","            self.models.sort(key=lambda x: -x[\"metrics\"])\n","\n","        elif ensemble_type == \"data\":\n","            self.models.sort(key=lambda x: -x[\"nsamples\"])\n","\n","        else:\n","            raise(ValueError(\"Incorrect `ensemble_type`\"))\n","\n","        self.ensemble = Ensemble(self.models[:k])\n","\n","    def receive(self, estimator, metrics, nsamples, Xt, yt, test_score):\n","        model = {\"estimator\": estimator, \"metrics\": metrics, \"nsamples\": nsamples,\n","                 \"X_test\": Xt, \"y_test\": yt, \"test_score\": test_score}\n","        self.models.append(model)\n","\n","\n","def load_data(digit, n_devices, min_sample=100, max_sample=500):\n","    # Load data\n","    data_mnist = np.load(r'../data/mnist-sampled-N10000.npz')\n","    X = data_mnist['arr_0'] / 255.0\n","    y = np.int64(data_mnist['arr_1'] < digit)\n","\n","    devices = []\n","    num_nsamples = np.random.lognormal(3, 2, (n_devices)).astype(int) # sample indices\n","    num_nsamples = [min(s + min_sample, max_sample) for s in num_nsamples]\n","    for c_id, c_nsamples in enumerate(num_nsamples):\n","        idx = np.array(random.sample(range(X.shape[0]), c_nsamples))\n","        X_train, X_test, y_train, y_test = train_test_split(X[idx], y[idx], test_size=0.3, random_state=0)\n","        devices.append(Device(c_id, y_train.shape[0], X_train, y_train, X_test, y_test))\n","    return devices\n","\n","\n","def protocol(digit, n_devices):\n","    devices = load_data(digit, n_devices)\n","    server = Server()\n","    for i, device in enumerate(devices):\n","        if 0.1*device.nsamples < np.sum(device.y) < 0.9*device.nsamples:\n","            device.train()\n","            server.receive(*device.send())\n","    return server, devices"],"metadata":{"id":"Bw6YB59GwC9B","executionInfo":{"status":"ok","timestamp":1700668168591,"user_tz":-480,"elapsed":4,"user":{"displayName":"Gamma Beta","userId":"01005985492029512712"}}},"execution_count":130,"outputs":[]},{"cell_type":"code","source":["server, devices = protocol(digit=6, n_devices=300)"],"metadata":{"id":"RY38N3TtZysB","executionInfo":{"status":"ok","timestamp":1700668407854,"user_tz":-480,"elapsed":221318,"user":{"displayName":"Gamma Beta","userId":"01005985492029512712"}}},"execution_count":131,"outputs":[]},{"cell_type":"code","source":["test_local_model = np.mean([model['test_score'] for model in server.models])\n","\n","server.build_ensemble(k=30, ensemble_type=\"random\")\n","test_ensemble_random = np.mean([accuracy_score(model['y_test'],\n","                                               server.ensemble.predict(model['X_test']) > 0.5\n","                                               ) for model in server.models])\n","\n","server.build_ensemble(k=30, ensemble_type=\"cv\")\n","test_ensemble_cv = np.mean([accuracy_score(model['y_test'],\n","                                               server.ensemble.predict(model['X_test']) > 0.5\n","                                               ) for model in server.models])\n","\n","server.build_ensemble(k=30, ensemble_type=\"data\")\n","test_ensemble_data = np.mean([accuracy_score(model['y_test'],\n","                                               server.ensemble.predict(model['X_test']) > 0.5\n","                                               ) for model in server.models])"],"metadata":{"id":"NNXzndI7egOm","executionInfo":{"status":"ok","timestamp":1700668686215,"user_tz":-480,"elapsed":242387,"user":{"displayName":"Gamma Beta","userId":"01005985492029512712"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["[test_local_model,\n"," test_ensemble_random,\n"," test_ensemble_cv,\n"," test_ensemble_data]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mExwEeFhgKB","executionInfo":{"status":"ok","timestamp":1700668691566,"user_tz":-480,"elapsed":7,"user":{"displayName":"Gamma Beta","userId":"01005985492029512712"}},"outputId":"1461873a-408a-4639-c136-2b226096698a"},"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.808736776363779, 0.882190872722728, 0.9084644669913462, 0.925573049832254]"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","source":["from sklearn.neural_network import MLPRegressor\n","\n","def distill(X, y, server):\n","    y = server.ensemble.predict(X)\n","    model = MLPRegressor(solver=\"lbfgs\", alpha=2e-5, hidden_layer_sizes=(5, 2), activation=\"logistic\")\n","    model.fit(X, y)\n","    return model"],"metadata":{"id":"p-fPvBL_C00-","executionInfo":{"status":"ok","timestamp":1700674952658,"user_tz":-480,"elapsed":449,"user":{"displayName":"Gamma Beta","userId":"01005985492029512712"}}},"execution_count":140,"outputs":[]}]}